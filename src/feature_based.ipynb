{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install vector database\n",
    "# ! pip install vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import torch\n",
    "import clip\n",
    "import json as js\n",
    "from docarray import DocList, BaseDoc\n",
    "from docarray.typing import NdArray\n",
    "import numpy as np\n",
    "from vectordb import InMemoryExactNNVectorDB, HNSWVectorDB\n",
    "from IPython.display import clear_output\n",
    "from natsort import natsorted\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import webbrowser\n",
    "import shutil\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"ViT-B/32\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "METADATA_PATH = \"../data/metadata/\"\n",
    "KEYFRAME_PATH = \"../data/keyframes/\"\n",
    "FEATURE_PATH = \"../data/features/\"\n",
    "MAP_KEYFRAMES = \"../data/map-keyframes/\"\n",
    "VIDEOS_PATH = \"../data/videos/\"\n",
    "SCRIPT_PATH = \"../data/scripts/\"\n",
    "\n",
    "WORKSPACE = \"./vectordb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify scripts\n",
    "print(len(os.listdir(VIDEOS_PATH)))\n",
    "print(len(os.listdir(SCRIPT_PATH)))\n",
    "print(len(os.listdir(VIDEOS_PATH)) == len(os.listdir(SCRIPT_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-formating Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get video names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_OF_KEYFRAME_NAME = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_names = [name for name in os.listdir(KEYFRAME_PATH) if name != \".gitkeep\"]\n",
    "print(video_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in video_names:\n",
    "    keyframes = [path for path in os.listdir(os.path.join(KEYFRAME_PATH, name))]\n",
    "    for kf in keyframes:\n",
    "        img_name = kf.split(\".\")[0]\n",
    "        if len(img_name) != LEN_OF_KEYFRAME_NAME:\n",
    "            changed_path = os.path.join(KEYFRAME_PATH, name, img_name.zfill(4) + \".jpg\")\n",
    "            old_path = os.path.join(KEYFRAME_PATH, name, kf)\n",
    "            print(f\"Change {old_path} to {changed_path}\")\n",
    "            os.rename(old_path, changed_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedding():\n",
    "  def __init__(self):\n",
    "    self.device = DEVICE\n",
    "    self.model, _ = clip.load(MODEL, device=self.device)\n",
    "\n",
    "  def __call__(self, text: str) -> np.ndarray:\n",
    "    text_inputs = clip.tokenize([text]).to(self.device)\n",
    "    with torch.no_grad():\n",
    "        text_feature = self.model.encode_text(text_inputs)[0]\n",
    "    return text_feature.detach().cpu().numpy()\n",
    "  \n",
    "  def __call__(self, texts) -> np.ndarray:\n",
    "    text_inputs = clip.tokenize(texts).to(self.device)\n",
    "    with torch.no_grad():\n",
    "        text_feature = self.model.encode_text(text_inputs)[0]\n",
    "    return text_feature.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding = TextEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A blue sky in the background\"\n",
    "query_feat = text_embedding(query)\n",
    "print(len(query_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys = [\"A blue sky in the background\", \"People hangout at the beach\", \"Birds are flying in the sky\"]\n",
    "querys_feat = text_embedding(querys)\n",
    "print(len(querys_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Document Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameDoc(BaseDoc):\n",
    "  embedding: NdArray[512]\n",
    "  video_name = \"\"\n",
    "  image_path = \"\"\n",
    "  keyframe_id = 0\n",
    "  actual_idx = 0\n",
    "  metadata = {}\n",
    "  \n",
    "  def __str__(self):\n",
    "    return f\"\"\"\n",
    "            Video name: {self.video_name}\n",
    "            Image path: {self.image_path}\n",
    "            Keyframe Id: {self.keyframe_id}\n",
    "            Actual keyframe idx: {self.actual_idx}\n",
    "            Metadata: {self.metadata}\n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Database Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDB: \n",
    "    text_embedding = TextEmbedding()\n",
    "    workspace = os.getcwd()\n",
    "    method = \"ANN\"\n",
    "    def __init__(self, method=\"ANN\"):\n",
    "        # Check if parent workspace exists\n",
    "        if not os.path.isdir(WORKSPACE):\n",
    "            os.mkdir(WORKSPACE, 0o666)\n",
    "        # Create new workspae\n",
    "        exits = [int(name.rsplit(\"_\")[1]) for name in os.listdir(WORKSPACE)]\n",
    "        while True:\n",
    "            id = random.getrandbits(128)\n",
    "            if id not in exits:\n",
    "                self.workspace = os.path.join(self.workspace, WORKSPACE, \"DB_\" + str(id))\n",
    "                break\n",
    "            \n",
    "        self.method = method\n",
    "        #   Approximate Nearest Neighbour based on HNSW algorithm\n",
    "        if method == \"ANN\":\n",
    "            self.DB = HNSWVectorDB[FrameDoc](workspace=self.workspace)\n",
    "            \n",
    "        # Exhaustive search on the embeddings\n",
    "        else:\n",
    "            self.DB = InMemoryExactNNVectorDB[FrameDoc](workspace=self.workspace)\n",
    "        \n",
    "        \n",
    "    def index(self, doc_list: List[FrameDoc]):    \n",
    "        # Index database\n",
    "        self.DB.index(inputs=DocList[FrameDoc](doc_list))\n",
    "        \n",
    "    def search(self, query_text: str, topk=100):\n",
    "        query_doc = FrameDoc(embedding=self.text_embedding(query_text))\n",
    "        return self.DB.search(inputs=DocList[FrameDoc]([query_doc]), limit=topk)[0].matches\n",
    "    \n",
    "    def delete(self, del_doc_list: List[FrameDoc]):\n",
    "        self.DB.delete(docs=DocList[FrameDoc](del_doc_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all features files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_feats():\n",
    "    return [os.path.join(FEATURE_PATH, file) for file in os.listdir(FEATURE_PATH) if file.endswith(\".npy\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat_files = get_all_feats()\n",
    "print(all_feat_files)\n",
    "print(len(all_feat_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all the Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_docs(npy_files):\n",
    "    doc_list = []\n",
    "    for feat_npy in npy_files:\n",
    "        video_name = feat_npy[feat_npy.find(\"L\"):].split('.')[0]\n",
    "        feats_arr = np.load(os.path.join(feat_npy))\n",
    "        # Load metadata\n",
    "        metadata = {}\n",
    "        with open(os.path.join(METADATA_PATH, video_name + \".json\")) as meta_f:\n",
    "            metadata = js.load(meta_f)\n",
    "            map_kf = pd.read_csv(os.path.join(MAP_KEYFRAMES, video_name + \".csv\"), usecols=[\"pts_time\", \"frame_idx\"])\n",
    "            metadata =  {key: metadata[key] for key in [\"publish_date\", \"watch_url\"]}\n",
    "            for frame_idx, feat in enumerate(feats_arr):\n",
    "                image_path = os.path.join(KEYFRAME_PATH, video_name, f\"{frame_idx + 1:04d}.jpg\")\n",
    "                frame_metadata = metadata.copy()\n",
    "                frame_metadata[\"watch_url\"] = frame_metadata[\"watch_url\"]  + \"&t=\" + str(map_kf[\"pts_time\"][frame_idx]) + \"s\"\n",
    "                actual_idx=map_kf[\"frame_idx\"][frame_idx]\n",
    "                doc_list.append(\n",
    "                                FrameDoc(\n",
    "                                        embedding=feat, \n",
    "                                        video_name=video_name, \n",
    "                                        image_path=image_path, \n",
    "                                        keyframe_id=frame_idx+1, \n",
    "                                        actual_idx=actual_idx, \n",
    "                                        metadata=frame_metadata\n",
    "                                        )\n",
    "                                )\n",
    "                \n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = get_all_docs(all_feat_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_list[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open video at specific times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_video(doc: FrameDoc):\n",
    "    webbrowser.open(doc.metadata[\"watch_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(results):\n",
    "    images = []\n",
    "    for i, res in enumerate(results):\n",
    "        img = Image.open(res.image_path)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 50)\n",
    "        draw.text(xy=(5, 5), text=f\"{i}, {res.video_name}, {res.actual_idx}\", align=\"left\", fill=(255,0,0,255), font=font)\n",
    "        images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(imgs: List[Image.Image]) -> None:\n",
    "    rows = len(imgs) // 2 # see more clearly\n",
    "    if not rows:\n",
    "        rows += 1\n",
    "    cols = len(imgs) // rows\n",
    "    if rows * cols < len(imgs):\n",
    "        rows += 1\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols * w, rows * h))\n",
    "    grid_w, grid_h = grid.size\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        \n",
    "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "\n",
    "    display(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = VectorDB()\n",
    "DB.index(doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đoạn video về một chiếc xe 7 chỗ biển số màu vàng hiệu Toyota tông vào gốc cây bên lề đường. Bên cạnh chiếc xe có biển báo giao nhau với đường không ưu tiên. Trong đoạn video có cảnh một người bảo vệ áo màu xanh đang nằm trên chiếc xe máy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = DB.search(\"Three men are running. On the left of the frame is a row of small green trees next to scattered items, and on the right is a carpet of grass.\", 1000) # Nên lấy nhiều"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "images = get_images(results1[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_video(results1[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB2 = VectorDB()\n",
    "DB2.index(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = DB2.search(\"A bag is on the road\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "visualize(get_images(results2[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_video(results2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results2[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "images = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
